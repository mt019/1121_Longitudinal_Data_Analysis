\documentclass[UTF8,a4paper,10pt]{article}

\input{preamble.tex}

% \begin{equation*}
%   \begin{aligned}
%   \end{aligned}
% \end{equation*}

% \begin{mybox}{}
% \end{mybox}


% \begin{Problem}[]{}
% \end{Problem}

% \begin{solution}\,
% \end{solution}
  

% \begin{enumerate}[label=(\alph*)]
% \end{enumerate} 

% \setcounter{section}{3} 
% \setcounter{theorem}{3}

% \begin{theorem}\label{thm:3.4}
%   If $E = \bigcup_{k} E_k$ is a countable union of sets, then $|E|_e \leq \sum_{k} |E_k|_e$.
%   \end{theorem}

%  \footcite[][42]{Wheeden_Zygmund_2015}

\begin{document}


% \begin{mybox}{}


% \end{mybox}

\begin{Problem}[]{Testing for completely random dropouts}

    Let \(P_{ij}\) denote the probability that the \(i-\)th unit drops out at time \(t_j\), \(j = 1,\ldots,m\).

    Under the assumption of completely random dropouts, the probability \(P_{ij}\) may depend on time, treatment, or other explanatory variables, but cannot depend on the observed measurements \(y_{i} = (y_{i1}, \ldots, y_{i\,m_i})\).

    \section*{Testing Method:}
    \begin{enumerate}[label=(\alph*)]
        \item Choose the score function \(h_{k}(y_{1},\ldots,y_{k})\) so that extreme values constitute evidence against completely random dropouts. A sensible choice is 
        \[h_{k}(y_{1},\ldots,y_{k}) = \sum_{j=1}^{k}\omega_{j}y_{j}.\]
        \item For each of \(k = 1, \ldots, (m-1)\), define
        \begin{align*}
            R_{k} = \{i:m_i\geq k\},\\
            r_{k} = \{i:m_i = k\},
        \end{align*}
        and compute the set of scores \(h_{ik} = h_k(y_{i1\ldots,y_{ik}})\) for \(i\in R_{k}\).
        \item If \(1\leq |r_k|\leq |R_k|\), test the hypothesis that the \(r_k\)'s scores so defined are a random sample from the "populations" of \(R_k\)'s scores.
    \end{enumerate}
---

Remark:

\begin{enumerate}
    \item The implicit assumption that the separated \(p-\)values are mutually independent is valid precisely because once a unit drops out, it never returns. 
    \item A natural test statistics is \(\widebar{h}_k = \frac{1}{|r_k|} \sum_{\{j\in r_k\}} h_{jk}\). Under the assumption of completely random dropouts, 
    \[\widebar{h}_k \sim N\left(\widebar{H}_k, \frac{|R_k|-|r_k|}{(|R_k|-1)|r_k|}\sum_{\{j\in R_k\}} (h_{jk}-\widebar{H}_{k})^2/|R_k|\right),\]
    where \[\widebar{H}_{k} = \frac{1}{|R_k|} \sum_{\{j\in r_k\}} h_{jk}.\]
    \begin{itemize}
        \item When \(|R_k|\) or \(|r_k|\) is small, evaluate the randomization distribution of \(\widebar{h}_k\) under the null hypothesis.
        \item Alternative method ...
    \end{itemize}
    \item The Final stage consists of analyzing the resulting set of \(p-\)values via 
    \begin{enumerate}
        \item Empirical distribution of the \(p-\)values
        \item Kolmogorov-Smirnov statistic \(D_{+} = \sup |\hat{F}_n(p)-p|\)
    \end{enumerate}
\end{enumerate}
\end{Problem}

Given a finite population of size \(N\), with individual values \(\{X_i\}_{i=1}^{N}\), 

and a set of sample of size \(n\), drawn from the population without replacement, with values \(\{X_i\}_{i=1}^{n}\).

Let $\sigma^2$ be the population variance:
\[\sigma^2 = \Var[X_i] = \frac{1}{N}\sum_{i=1}^{N}(X_i-\mu),\]
where \(\mu = \sum_{i=1}^{N} X_i\) is the population mean.

Let \(\bar{X} = \frac{1}{n}S_n = \frac{1}{n}\sum_{i=1}^{n}X_i\) be the sample mean based on the sample set.



Since every pair $(X_i, X_j)$ for $i \neq j$ has the same joint distribution, we have
% the variance of the sum $S_n := X_1 + \ldots + X_n$ is
\begin{align*}
    \Var[S_n] = \sum_{i=1}^{n}\sum_{j=1}^{n}\Cov[X_i,X_j],
\end{align*}
where 
\[\Cov[X_i,X_j] = \begin{cases}
     \sigma^2 & i=j\\
    c  & i\neq j\\
\end{cases}.\]
Thus,
\begin{align*}
    \Var[S_n] 
    % &= n \Var[X_i]+ \left(n^2 - n\right)\Cov[X_i, X_j] \\
    &= n\sigma^2 + n(n-1)c.\label{eq.01}
\end{align*}
% \[
% \Var[S_n] = n \Var[X_i]+ \left(n^2 - n\right)\Cov(X_i, X_j) = n\sigma^2 + n(n-1)c.
% \]
% where we write $c$ for the covariance between the results of two distinct draws. Formula (1) 
which applies to the case $n=N$ as well. Notice that $S_N$ is a constant (equal to the sum of all $N$ values in the population). It follows that
\[
0 = \Var[S_N] = N\sigma^2 + N(N-1)c.
\]
Solve the equation above for $$c = -\frac{\sigma^2}{N-1}.$$

Hence,
\[
\Var[S_n] = n\sigma^2\left(1 - \frac{n-1}{N-1}\right) = \frac{N-n}{N-1} \cdot n\sigma^2
\]
and
\[
\Var[\bar{X}] = \frac{N-n}{N-1} \cdot \frac{\sigma^2}{n}.
\]

The factor \(\dfrac{N-n}{N-1}\) is the Finite Population Correction Factor (FPC).
% Notice the difference between formulas (4) and (5) and the corresponding formulas for sampling with replacement is a factor $\frac{N-n}{N-1}$, which is the famous correction factor for sampling without replacement.


\end{document}

